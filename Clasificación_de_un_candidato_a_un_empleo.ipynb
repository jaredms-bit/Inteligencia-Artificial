{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3AhJGlIW1hIc9aLE3+NAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredms-bit/Inteligencia-Artificial/blob/main/Clasificaci%C3%B3n_de_un_candidato_a_un_empleo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clasificación de un candidato a un empleo"
      ],
      "metadata": {
        "id": "zSurdq7Lu3zK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tcBFM5Zfu0Tu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Voy a generar una base de datos falsa con diferentes tipos de habilidades para 5000 personas\n",
        "n_muestras = 5000\n",
        "\n",
        "# Aquí creo 6 columnas de habilidades técnicas (como Python, SQL, etc.)\n",
        "# Los valores van de 70 a 100, o sea, son puntajes altos en esas habilidades\n",
        "tec = np.random.randint(70, 101, (n_muestras, 6))\n",
        "\n",
        "# Ahora creo 6 columnas de habilidades matemáticas (como probabilidad o cálculo)\n",
        "# Los valores van de 60 a 90, o sea, un nivel medio-alto en matemáticas\n",
        "mat = np.random.randint(60, 91, (n_muestras, 6))\n",
        "\n",
        "# Aquí genero 6 columnas de habilidades psicológicas (como trabajo en equipo o liderazgo)\n",
        "# Los valores van de 50 a 85, un poco más bajos que los anteriores\n",
        "psi = np.random.randint(50, 86, (n_muestras, 6))\n",
        "\n",
        "# Estos son los nombres de todas las columnas que tendrá la tabla\n",
        "columnas = [\n",
        "    'python', 'sql', 'visualizacion_datos', 'excel', 'manejo_apis', 'nube',\n",
        "    'estadistica', 'probabilidad', 'algebra_lineal', 'calculo', 'optimizacion', 'modelado',\n",
        "    'trabajo_equipo', 'comunicacion', 'creatividad', 'adaptabilidad', 'liderazgo', 'resolucion_problemas'\n",
        "]\n",
        "\n",
        "# Aquí uno (junto) todas las habilidades técnicas, matemáticas y psicológicas en una sola tabla\n",
        "# y creo un DataFrame (una especie de tabla de datos) con pandas llamado df\n",
        "df = pd.DataFrame(np.concatenate([tec, mat, psi], axis=1), columns=columnas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos la etiqueta\n"
      ],
      "metadata": {
        "id": "Sq1fpS8dvdtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular promedio por grupo y promedio total\n",
        "# Calculamos el promedio de todas las columnas relacionadas con habilidades tecnológicas (prom_tecnologicas) para cada fila (axis=1) del dataframe 'df'\n",
        "prom_tecnologicas = df[['python', 'sql', 'visualizacion_datos', 'excel', 'manejo_apis', 'nube']].mean(axis=1)\n",
        "\n",
        "# Calculamos el promedio de todas las columnas relacionadas con habilidades matemáticas (prom_matematicas) para cada fila (axis=1) del dataframe 'df'\n",
        "prom_matematicas = df[['estadistica', 'probabilidad', 'algebra_lineal', 'calculo', 'optimizacion', 'modelado']].mean(axis=1)\n",
        "\n",
        "# Calculamos el promedio de todas las columnas relacionadas con habilidades psicológicas o blandas (prom_psicologicas) para cada fila (axis=1) del dataframe 'df'\n",
        "prom_psicologicas = df[['trabajo_equipo', 'comunicacion', 'creatividad', 'adaptabilidad', 'liderazgo', 'resolucion_problemas']].mean(axis=1)\n",
        "\n",
        "# Promedio total = promedio de los 3 promedios\n",
        "# Calculamos el promedio general sumando los tres promedios de grupo que acabamos de obtener y dividiéndolos entre 3\n",
        "prom_total = (prom_tecnologicas + prom_matematicas + prom_psicologicas) / 3\n",
        "\n",
        "# Etiqueta: 1 = apto si promedio total > 75 (el valor era 80, pero lo cambiaste a 75)\n",
        "# Creamos la variable 'y' que toma el valor 1 (apto) si el promedio total es mayor a 75, y 0 (no apto) si es 75 o menos. Luego, convertimos esos True/False a 1/0 (int)\n",
        "y = (prom_total > 75).astype(int)\n",
        "\n",
        "# one-hot encoding\n",
        "# Convertimos la variable 'y' (que tiene 0s y 1s) en dos columnas binarias separadas (one-hot encoding) y tomamos solo los valores (values) para usarlo en un modelo\n",
        "y = pd.get_dummies(y).values"
      ],
      "metadata": {
        "id": "VabIhdaavfGX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos los conjuntos de entrenamiento"
      ],
      "metadata": {
        "id": "BxIjHQC5vyMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la función que nos permite dividir nuestro conjunto de datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos el conjunto de datos completo (df, que son las características o X) y las etiquetas (y) en cuatro partes:\n",
        "# 1. X_train: Las características que usaremos para entrenar el modelo (el 80% de los datos)\n",
        "# 2. X_test: Las características que usaremos para probar el modelo (el 20% de los datos)\n",
        "# 3. y_train: Las etiquetas correspondientes a X_train\n",
        "# 4. y_test: Las etiquetas correspondientes a X_test\n",
        "# test_size=0.2: Le decimos que el 20% de los datos se use para prueba.\n",
        "# random_state=42: Aseguramos que la división sea siempre la misma cada vez que ejecutamos el código.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Escalamiento (o estandarización de los datos)\n",
        "# Importamos la herramienta que usaremos para hacer que todas nuestras variables (características) tengan una distribución similar (media 0 y desviación estándar 1).\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creamos una \"máquina\" o un objeto de estandarización.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 1. Entrenamos la \"máquina\" (fit) para que calcule la media y desviación estándar SOLAMENTE de nuestros datos de entrenamiento (X_train).\n",
        "# 2. Luego, aplicamos esa transformación (transform) a X_train para estandarizarlo.\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Aplicamos la transformación (transform) a nuestros datos de prueba (X_test) usando la misma media y desviación estándar que aprendimos de X_train.\n",
        "# ¡Es importante no usar 'fit' en X_test para evitar hacer trampa o 'filtrar' información al modelo!\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EPvQZQvrv17Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Red neuronal"
      ],
      "metadata": {
        "id": "-0JNlwR6v_D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las herramientas necesarias de Keras para construir y configurar una Red Neuronal\n",
        "from tensorflow.keras.models import Sequential # 'Sequential' nos permite apilar capas una tras otra (el modelo más simple)\n",
        "from tensorflow.keras.layers import Dense # 'Dense' es el tipo de capa más común, donde todas las neuronas están conectadas\n",
        "from tensorflow.keras.optimizers import Adam # 'Adam' es un optimizador muy popular para entrenar la red\n",
        "\n",
        "# Creamos el modelo de red neuronal. 'Sequential' significa que vamos a poner las capas en orden, una detrás de otra.\n",
        "modelo = Sequential([\n",
        "    # Primera capa (Capa de entrada):\n",
        "    # Tendrá 64 neuronas.\n",
        "    # 'input_shape=(X_train.shape[1],)': Le decimos que la forma de entrada es igual al número de columnas (características) en nuestro conjunto de entrenamiento (X_train).\n",
        "    # 'activation='relu'': Usamos la función de activación ReLU, que ayuda a la red a aprender relaciones no lineales.\n",
        "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "\n",
        "    # Segunda capa (Capa oculta):\n",
        "    # Tendrá 32 neuronas. Usamos ReLU como función de activación.\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    # Tercera capa (Otra capa oculta):\n",
        "    # Tendrá 16 neuronas. Usamos ReLU como función de activación.\n",
        "    Dense(16, activation='relu'),\n",
        "\n",
        "    # Cuarta capa (Capa de salida):\n",
        "    # Tendrá 2 neuronas, que es el número de clases de salida (apto o no apto, porque usamos one-hot encoding).\n",
        "    # 'activation='softmax'': Usamos Softmax para la clasificación. Convierte las salidas en probabilidades, asegurando que la suma de ambas neuronas sea 1.\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Configuramos el optimizador\n",
        "# Creamos el optimizador Adam y le establecemos una \"tasa de aprendizaje\" (learning_rate) pequeña de 0.001.\n",
        "# Esta tasa controla qué tan grandes son los pasos que da el modelo para corregir errores durante el entrenamiento.\n",
        "adam = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compilamos el modelo (lo preparamos para el entrenamiento)\n",
        "# Le decimos al modelo cómo debe aprender:\n",
        "# 'optimizer=adam': Usaremos el optimizador Adam que acabamos de configurar.\n",
        "# 'loss='categorical_crossentropy'': Esta es la función que mide qué tan mal está el modelo prediciendo; se usa porque tenemos más de dos clases en formato one-hot encoding.\n",
        "# 'metrics=['accuracy']': Le pedimos que, mientras entrena, nos muestre la 'precisión' (accuracy) para que podamos evaluar qué tan bien lo está haciendo.\n",
        "modelo.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUeJrzwJwB8c",
        "outputId": "ccc7a8cd-cb50-4fdd-f57e-030fd95e007b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento"
      ],
      "metadata": {
        "id": "d4yDWK8OwLrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo y guardamos el resultado del proceso en una variable llamada 'history'\n",
        "# 'history' nos permitirá ver después cómo se comportó el modelo (pérdida, precisión) durante el entrenamiento.\n",
        "history = modelo.fit(\n",
        "    # Datos de Entrenamiento:\n",
        "    X_train, y_train, # Le damos las características (X_train) y las etiquetas correctas (y_train) para que aprenda.\n",
        "\n",
        "    # Hiperparámetros de Entrenamiento:\n",
        "    # epochs=50: Le decimos que repita el proceso completo de entrenamiento (pasar por todos los datos) 50 veces. Cada repetición es una 'época'.\n",
        "    epochs=50,\n",
        "\n",
        "    # batch_size=8: Le indicamos que procese los datos en grupos pequeños de 8 muestras a la vez.\n",
        "    # Después de cada grupo de 8, el modelo actualiza sus 'pesos' internos. Usar lotes pequeños ayuda a que el aprendizaje sea más fino.\n",
        "    batch_size=8,\n",
        "\n",
        "    # Evaluación durante el entrenamiento:\n",
        "    # validation_data=(X_test, y_test): Le pedimos que, al final de cada 'época', evalúe qué tan bien le va con los datos de prueba (X_test y y_test),\n",
        "    # que son datos que no ha usado para aprender. Esto nos ayuda a detectar si el modelo está sufriendo 'sobreajuste' (overfitting).\n",
        "    validation_data=(X_test, y_test),\n",
        "\n",
        "    # Visualización:\n",
        "    # verbose=1: Le decimos que queremos ver el progreso del entrenamiento en la pantalla (una línea por cada época).\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asmiaxdWwOgz",
        "outputId": "a1ca5278-2932-43e5-ee94-8015b6a02b99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8237 - loss: 0.3930 - val_accuracy: 0.9650 - val_loss: 0.0850\n",
            "Epoch 2/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.0851 - val_accuracy: 0.9750 - val_loss: 0.0560\n",
            "Epoch 3/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0498 - val_accuracy: 0.9770 - val_loss: 0.0500\n",
            "Epoch 4/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0411 - val_accuracy: 0.9740 - val_loss: 0.0487\n",
            "Epoch 5/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0265 - val_accuracy: 0.9790 - val_loss: 0.0498\n",
            "Epoch 6/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0277 - val_accuracy: 0.9770 - val_loss: 0.0643\n",
            "Epoch 7/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0147 - val_accuracy: 0.9810 - val_loss: 0.0555\n",
            "Epoch 8/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 0.9700 - val_loss: 0.0857\n",
            "Epoch 9/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.9790 - val_loss: 0.0656\n",
            "Epoch 10/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0096 - val_accuracy: 0.9730 - val_loss: 0.0854\n",
            "Epoch 11/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0127 - val_accuracy: 0.9800 - val_loss: 0.0616\n",
            "Epoch 12/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.9750 - val_loss: 0.0664\n",
            "Epoch 13/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0052 - val_accuracy: 0.9750 - val_loss: 0.0594\n",
            "Epoch 14/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0064 - val_accuracy: 0.9780 - val_loss: 0.0546\n",
            "Epoch 15/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0219 - val_accuracy: 0.9770 - val_loss: 0.0595\n",
            "Epoch 16/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0133 - val_accuracy: 0.9810 - val_loss: 0.0616\n",
            "Epoch 17/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0055 - val_accuracy: 0.9790 - val_loss: 0.0733\n",
            "Epoch 18/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.9760 - val_loss: 0.0959\n",
            "Epoch 19/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0118 - val_accuracy: 0.9750 - val_loss: 0.0664\n",
            "Epoch 20/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9840 - val_loss: 0.0406\n",
            "Epoch 21/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9623e-04 - val_accuracy: 0.9800 - val_loss: 0.0399\n",
            "Epoch 22/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4786e-04 - val_accuracy: 0.9810 - val_loss: 0.0423\n",
            "Epoch 23/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3715e-04 - val_accuracy: 0.9830 - val_loss: 0.0436\n",
            "Epoch 24/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.7260e-05 - val_accuracy: 0.9810 - val_loss: 0.0459\n",
            "Epoch 25/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2832e-05 - val_accuracy: 0.9830 - val_loss: 0.0464\n",
            "Epoch 26/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1032e-05 - val_accuracy: 0.9840 - val_loss: 0.0433\n",
            "Epoch 27/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3674e-05 - val_accuracy: 0.9830 - val_loss: 0.0471\n",
            "Epoch 28/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0460e-05 - val_accuracy: 0.9830 - val_loss: 0.0467\n",
            "Epoch 29/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1533e-05 - val_accuracy: 0.9830 - val_loss: 0.0491\n",
            "Epoch 30/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7326e-05 - val_accuracy: 0.9830 - val_loss: 0.0481\n",
            "Epoch 31/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2852e-05 - val_accuracy: 0.9830 - val_loss: 0.0488\n",
            "Epoch 32/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6847e-06 - val_accuracy: 0.9840 - val_loss: 0.0496\n",
            "Epoch 33/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2580e-06 - val_accuracy: 0.9830 - val_loss: 0.0515\n",
            "Epoch 34/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5043e-06 - val_accuracy: 0.9850 - val_loss: 0.0507\n",
            "Epoch 35/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5703e-06 - val_accuracy: 0.9840 - val_loss: 0.0530\n",
            "Epoch 36/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2372e-06 - val_accuracy: 0.9840 - val_loss: 0.0565\n",
            "Epoch 37/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0261e-06 - val_accuracy: 0.9840 - val_loss: 0.0529\n",
            "Epoch 38/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.7066e-06 - val_accuracy: 0.9840 - val_loss: 0.0546\n",
            "Epoch 39/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.2176e-06 - val_accuracy: 0.9850 - val_loss: 0.0553\n",
            "Epoch 40/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3851e-07 - val_accuracy: 0.9850 - val_loss: 0.0608\n",
            "Epoch 41/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4375e-07 - val_accuracy: 0.9850 - val_loss: 0.0586\n",
            "Epoch 42/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7528e-07 - val_accuracy: 0.9850 - val_loss: 0.0600\n",
            "Epoch 43/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5217e-07 - val_accuracy: 0.9850 - val_loss: 0.0612\n",
            "Epoch 44/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7226e-07 - val_accuracy: 0.9850 - val_loss: 0.0637\n",
            "Epoch 45/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1897e-07 - val_accuracy: 0.9850 - val_loss: 0.0614\n",
            "Epoch 46/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4865e-07 - val_accuracy: 0.9850 - val_loss: 0.0654\n",
            "Epoch 47/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3734e-07 - val_accuracy: 0.9840 - val_loss: 0.0655\n",
            "Epoch 48/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4724e-08 - val_accuracy: 0.9840 - val_loss: 0.0654\n",
            "Epoch 49/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6465e-08 - val_accuracy: 0.9860 - val_loss: 0.0666\n",
            "Epoch 50/50\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8145e-08 - val_accuracy: 0.9850 - val_loss: 0.0686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de confusión"
      ],
      "metadata": {
        "id": "CZJVevI0wZ8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las herramientas que nos permiten evaluar el rendimiento de nuestro modelo de clasificación\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score\n",
        "import numpy as np # Necesitamos NumPy para trabajar con arreglos de manera eficiente\n",
        "import matplotlib.pyplot as plt # Necesitamos Matplotlib para poder mostrar la gráfica de la Matriz de Confusión\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Hacemos las Predicciones\n",
        "# Usamos el modelo entrenado para predecir las etiquetas de los datos de prueba (X_test). El resultado es una probabilidad por clase.\n",
        "pred = modelo.predict(X_test)\n",
        "\n",
        "# Convertimos las predicciones a etiquetas simples\n",
        "# 'pred' nos da una probabilidad para la clase 0 y una para la clase 1. Aquí, tomamos la clase con la probabilidad más alta (el índice, axis=1),\n",
        "# y ese índice se convierte en nuestra etiqueta predicha (0 o 1).\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "\n",
        "# Hacemos lo mismo con las etiquetas verdaderas\n",
        "# Como nuestras etiquetas originales (y_test) estaban en formato one-hot encoding (dos columnas), las convertimos de nuevo a etiquetas simples (0 o 1)\n",
        "# para que puedan ser comparadas directamente con nuestras predicciones (y_pred).\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Matriz de Confusión\n",
        "# Calculamos la matriz de confusión (cm). Esta tabla nos muestra cuántas predicciones fueron correctas (en la diagonal) y cuántas fueron incorrectas (fuera de la diagonal).\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Preparamos el gráfico de la matriz de confusión\n",
        "# Creamos un objeto para mostrar la matriz. Le pasamos la matriz 'cm' que calculamos y le damos los nombres que deben tener las etiquetas ('No Apto', 'Apto').\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Apto', 'Apto'])\n",
        "\n",
        "# Dibujamos y mostramos el gráfico de la matriz de confusión, usando un esquema de color azul.\n",
        "disp.plot(cmap='Blues')\n",
        "plt.show() # Mostramos la gráfica en pantalla\n",
        "#\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Sensibilidad (Recall)\n",
        "# Calculamos la métrica 'sensibilidad' (o recall) para cada clase (average=None).\n",
        "# La sensibilidad mide qué tan bien el modelo encuentra todos los casos positivos (verdaderos) de cada clase.\n",
        "sensitivity = recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "# Imprimimos los resultados\n",
        "print(\"\\nSensitivity (Recall) por clase:\")\n",
        "# Imprimimos la sensibilidad para la clase 0 ('No Apto'), con dos decimales.\n",
        "print(f\"No Apto: {sensitivity[0]:.2f}\")\n",
        "# Imprimimos la sensibilidad para la clase 1 ('Apto'), con dos decimales.\n",
        "print(f\"Apto: {sensitivity[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "1Kl_v8SLwdlm",
        "outputId": "202b1459-bb1b-4cb5-a792-101d425cf1b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sensitivity (Recall) por clase:\n",
            "No Apto: 0.99\n",
            "Apto: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar un nuevo candidato"
      ],
      "metadata": {
        "id": "0hnggJ3bwmNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------------------------------\n",
        "# 1. Preparación del Nuevo Candidato\n",
        "# Creamos un arreglo de NumPy (nuevo_candidato) con las 18 puntuaciones del individuo, respetando el orden de las columnas originales del DataFrame 'df'.\n",
        "# El orden es: 6 técnicas, 6 matemáticas, y 6 psicológicas.\n",
        "nuevo_candidato = np.array([[90, 88, 85, 87, 84, 89,    # Puntuaciones en habilidades técnicas\n",
        "                             82, 86, 85, 83, 87, 80,    # Puntuaciones en habilidades matemáticas\n",
        "                             70, 75, 80, 72, 78, 74]])  # Puntuaciones en habilidades psicológicas\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# 2. Escalamiento del Candidato\n",
        "# Aplicamos la misma estandarización (scaler.transform) que hicimos a los datos de entrenamiento (X_train).\n",
        "# ¡Es crucial usar el mismo 'scaler' para que los datos del nuevo candidato estén en la misma escala que los datos que el modelo aprendió!\n",
        "nuevo_candidato_scaled = scaler.transform(nuevo_candidato)\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# 3. Predicción del Modelo\n",
        "# Usamos el modelo entrenado (modelo.predict) para obtener las probabilidades de que el candidato pertenezca a cada clase,\n",
        "# usando los datos ya escalados. El resultado será un arreglo con dos valores (probabilidad de 0, probabilidad de 1).\n",
        "pred_nuevo = modelo.predict(nuevo_candidato_scaled)\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# 4. Decisión de la Clase\n",
        "# np.argmax(pred_nuevo): Encontramos el índice (0 o 1) que corresponde a la probabilidad más alta entre las dos salidas del modelo.\n",
        "# Este índice es la clase que el modelo predice para el candidato.\n",
        "clase_predicha = np.argmax(pred_nuevo)\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# 5. Presentación del Resultado\n",
        "# Imprimimos un mensaje claro. Usamos una expresión condicional:\n",
        "# Si la 'clase_predicha' es 1, imprimimos \"Apto\".\n",
        "# Si la 'clase_predicha' es 0, imprimimos \"No Apto\".\n",
        "print(\"Evaluación de nuevo candidato:\")\n",
        "print(f\"Resultado: {'Apto' if clase_predicha == 1 else 'No Apto'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYvPrY6Xwpp3",
        "outputId": "b36673c8-5c97-4465-9a8d-6bdaee4dd23c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Evaluación de nuevo candidato:\n",
            "Resultado: Apto\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}